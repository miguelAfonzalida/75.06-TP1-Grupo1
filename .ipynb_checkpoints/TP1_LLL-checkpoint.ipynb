{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import seaborn as sb\n",
    "from nltk.tokenize import WordPunctTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train.csv')\n",
    "df_countrys = pd.read_csv('data/country-keyword-list.csv')\n",
    "df_usa_cities1 = pd.read_csv('data/usa-cities1.csv')\n",
    "df_usa_cities2 = pd.read_csv('data/usa-cities2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      "id          7613 non-null int64\n",
      "keyword     7552 non-null object\n",
      "location    5080 non-null object\n",
      "text        7613 non-null object\n",
      "target      7613 non-null int64\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detectando hashtags y menciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = '\\s([@#][\\w_-]+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['#earthquake'],\n",
       " ['#wildfires'],\n",
       " ['#Alaska', '#wildfires'],\n",
       " ['#CAfire', '#wildfires'],\n",
       " ['#disaster'],\n",
       " ['#flooding'],\n",
       " ['#flooding', '#Florida', '#TampaBay', '#Tampa'],\n",
       " ['#We'],\n",
       " ['#BREAKING'],\n",
       " ['#metal', '#RT'],\n",
       " ['#mufc'],\n",
       " ['#Bridgetown'],\n",
       " ['#nsfw'],\n",
       " ['@southridgelife'],\n",
       " ['#nsfw'],\n",
       " ['#Diyala'],\n",
       " ['#California', '#climate', '#energy'],\n",
       " ['@News24680'],\n",
       " ['#EDM'],\n",
       " ['#NashvilleTraffic'],\n",
       " ['#SantaClara', '#BayArea', '#Traffic'],\n",
       " ['#personalinjury', '#solicitor', '#OtleyHour'],\n",
       " ['#caraccidentlawyer'],\n",
       " ['@SleepJunkies'],\n",
       " ['#FortWorth'],\n",
       " ['#Ashville', '#traffic'],\n",
       " ['#Manchester', '#traffic'],\n",
       " ['#Hagerstown', '@Your4State', '#WHAG']]"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos = df['text']\n",
    "resultados = []\n",
    "for t in testing:\n",
    "    matched = re.findall(regex,t)\n",
    "    if (len(matched) > 0):\n",
    "        resultados.append(matched)\n",
    "resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags = []\n",
    "mentions = []\n",
    "for i in resultados:\n",
    "    for j in i:\n",
    "        if ('@' in j):\n",
    "            mentions.append(j)\n",
    "        else:\n",
    "            hashtags.append(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['#earthquake',\n",
       " '#wildfires',\n",
       " '#Alaska',\n",
       " '#wildfires',\n",
       " '#CAfire',\n",
       " '#wildfires',\n",
       " '#disaster',\n",
       " '#flooding',\n",
       " '#flooding',\n",
       " '#Florida',\n",
       " '#TampaBay',\n",
       " '#Tampa',\n",
       " '#We',\n",
       " '#BREAKING',\n",
       " '#metal',\n",
       " '#RT',\n",
       " '#mufc',\n",
       " '#Bridgetown',\n",
       " '#nsfw',\n",
       " '#nsfw',\n",
       " '#Diyala',\n",
       " '#California',\n",
       " '#climate',\n",
       " '#energy',\n",
       " '#EDM',\n",
       " '#NashvilleTraffic',\n",
       " '#SantaClara',\n",
       " '#BayArea',\n",
       " '#Traffic',\n",
       " '#personalinjury',\n",
       " '#solicitor',\n",
       " '#OtleyHour',\n",
       " '#caraccidentlawyer',\n",
       " '#FortWorth',\n",
       " '#Ashville',\n",
       " '#traffic',\n",
       " '#Manchester',\n",
       " '#traffic',\n",
       " '#Hagerstown',\n",
       " '#WHAG']"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@southridgelife', '@News24680', '@SleepJunkies', '@Your4State']"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# esta info puede servir luego para detectar gente hablando sobre el mismo tema con un hashtag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpieza de tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = WordPunctTokenizer()\n",
    "#regular expression for eliminate @person\n",
    "pat1 = r'\\s([@#][\\w_-]+)'\n",
    "#regular expression for eliminate links\n",
    "pat2 = r'https?://[A-Za-z0-9./]+'\n",
    "combined_pat = r'|'.join((pat1, pat2))\n",
    "\n",
    "def tweet_cleaner(text):\n",
    "    #dealing with html encoding\n",
    "    soup = BeautifulSoup(text, 'lxml')\n",
    "    souped = soup.get_text()\n",
    "    #applying pattern regexs\n",
    "    stripped = re.sub(pat2, '', souped)\n",
    "    try:\n",
    "        clean = stripped.decode(\"utf-8-sig\").replace(u\"\\ufffd\", \"?\")\n",
    "    except:\n",
    "        clean = stripped\n",
    "    letters_only = re.sub(\"[^a-zA-Z]\", \" \", clean)\n",
    "    lower_case = letters_only.lower()\n",
    "    # During the letters_only process two lines above, it has created unnecessay white spaces,\n",
    "    # I will tokenize and join together to remove unneccessary white spaces\n",
    "    words = tok.tokenize(lower_case)\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['our deeds are the reason of this earthquake may allah forgive us all',\n",
       " 'forest fire near la ronge sask canada',\n",
       " 'all residents asked to shelter in place are being notified by officers no other evacuation or shelter in place orders are expected',\n",
       " 'people receive wildfires evacuation orders in california',\n",
       " 'just got sent this photo from ruby alaska as smoke from wildfires pours into a school',\n",
       " 'rockyfire update california hwy closed in both directions due to lake county fire cafire wildfires',\n",
       " 'flood disaster heavy rain causes flash flooding of streets in manitou colorado springs areas',\n",
       " 'i m on top of the hill and i can see a fire in the woods',\n",
       " 'there s an emergency evacuation happening now in the building across the street',\n",
       " 'i m afraid that the tornado is coming to our area',\n",
       " 'three people died from the heat wave so far',\n",
       " 'haha south tampa is getting flooded hah wait a second i live in south tampa what am i gonna do what am i gonna do fvck flooding',\n",
       " 'raining flooding florida tampabay tampa or days i ve lost count',\n",
       " 'flood in bago myanmar we arrived bago',\n",
       " 'damage to school bus on in multi car crash breaking',\n",
       " 'what s up man',\n",
       " 'i love fruits',\n",
       " 'summer is lovely',\n",
       " 'my car is so fast',\n",
       " 'what a goooooooaaaaaal',\n",
       " 'this is ridiculous',\n",
       " 'london is cool',\n",
       " 'love skiing',\n",
       " 'what a wonderful day',\n",
       " 'looooool',\n",
       " 'no way i can t eat that shit',\n",
       " 'was in nyc last week',\n",
       " 'love my girlfriend',\n",
       " 'cooool',\n",
       " 'do you like pasta',\n",
       " 'the end',\n",
       " 'bbcmtd wholesale markets ablaze',\n",
       " 'we always try to bring the heavy metal rt',\n",
       " 'africanbaze breaking news nigeria flag set ablaze in aba',\n",
       " 'crying out for more set me ablaze',\n",
       " 'on plus side look at the sky last night it was ablaze',\n",
       " 'phdsquares mufc they ve built so much hype around new acquisitions but i doubt they will set the epl ablaze this season',\n",
       " 'inec office in abia set ablaze',\n",
       " 'barbados bridgetown jamaica two cars set ablaze santa cruz head of the st elizabeth police superintende',\n",
       " 'ablaze for you lord d',\n",
       " 'check these out nsfw',\n",
       " 'on the outside you re ablaze and alive but you re dead inside',\n",
       " 'had an awesome time visiting the cfc head office the ancop site and ablaze thanks to tita vida for taking care of us',\n",
       " 'soooo pumped for ablaze southridgelife',\n",
       " 'i wanted to set chicago ablaze with my preaching but not my hotel',\n",
       " 'i gained followers in the last week you know your stats and grow with',\n",
       " 'how the west was burned thousands of wildfires ablaze in california alone',\n",
       " 'building the perfect tracklist to life leave the streets ablaze',\n",
       " 'check these out nsfw',\n",
       " 'first night with retainers in it s quite weird better get used to it i have to wear them every single night for the next year at least',\n",
       " 'deputies man shot before brighton home set ablaze',\n",
       " 'man wife get six years jail for setting ablaze niece',\n",
       " 'santa cruz head of the st elizabeth police superintendent lanford salmon has r',\n",
       " 'police arsonist deliberately set black church in north carolina ablaze',\n",
       " 'noches el bestia alexis sanchez happy to see my teammates and training hard goodnight gunners',\n",
       " 'kurds trampling on turkmen flag later set it ablaze while others vandalized offices of turkmen front in diyala',\n",
       " 'truck ablaze r voortrekker ave outside or tambo intl cargo section',\n",
       " 'set our hearts ablaze and every city was a gift and every skyline was like a kiss upon the lips',\n",
       " 'they sky was ablaze tonight in los angeles i m expecting ig and fb to be filled with sunset shots if i know my peeps',\n",
       " 'how the west was burned thousands of wildfires ablaze in california alone climate energy',\n",
       " 'revel in yours wmv videos by means of mac farewell ablaze wmv en route to dvd gtxrwm',\n",
       " 'progressive greetings in about a month students would have set their pens ablaze in the torch publications',\n",
       " 'rene ablaze jacinta secret k fallen skies edit mar',\n",
       " 'navista steve these fires out here are something else california is a tinderbox and this clown was setting my hood ablaze news',\n",
       " 'nowplaying rene ablaze ian buff magnitude edm',\n",
       " 'nxwestmidlands huge fire at wholesale markets ablaze',\n",
       " 'ablaze what time does your talk go until i don t know if i can make it due to work',\n",
       " 'i can t have kids cuz i got in a bicycle accident split my testicles it s impossible for me to have kids michael you are the father',\n",
       " 'accident on i w nashvilletraffic traffic moving m slower than usual',\n",
       " 'accident center lane blocked in santaclara on us nb before great america pkwy bayarea traffic',\n",
       " 'had a personalinjury accident this summer read our advice see how a solicitor can help otleyhour',\n",
       " 'stlouis caraccidentlawyer speeding among top causes of teen accidents car accident tee',\n",
       " 'reported motor vehicle accident in curry on herman rd near stephenson involving an overturned vehicle please use',\n",
       " 'bigrigradio live accident awareness',\n",
       " 'i mile marker south mooresville iredell vehicle accident ramp closed at pm',\n",
       " 'rt sleepjunkies sleeping pills double your risk of a car accident',\n",
       " 'by accident they knew what was gon happen',\n",
       " 'traffic accident n cabrillo hwy magellan av mir',\n",
       " 'i mile marker to south mooresville iredell vehicle accident congestion at pm',\n",
       " 'the pastor was not in the scene of the accident who was the owner of the range rover',\n",
       " 'mom we didn t get home as fast as we wished me why is that mom there was an accident and some truck spilt mayonnaise all over',\n",
       " 'i was in a horrible car accident this past sunday i m finally able to get around thank you god',\n",
       " 'can wait to see how pissed donnie is when i tell him i was in another accident',\n",
       " 'truckcrash overturns on fortworth interstate click here if you ve been in a crash',\n",
       " 'accident in ashville on us sb before sr traffic',\n",
       " 'carolina accident motorcyclist dies in i crash with car that crossed median a motorcycle rider traveling',\n",
       " 'fyi cad fyi accident property damage nhs piner rd horndale dr',\n",
       " 'rt naayf first accident in years turning onto chandanee magu from near mma taxi rammed into me while i was halfway turned everyone conf',\n",
       " 'accident left lane blocked in manchester on rt nb before eddy rd stop and go traffic back to nh a delay of mins traffic',\n",
       " 'accident property damage piner rd horndale dr',\n",
       " 'it was an accident',\n",
       " 'fyi cad fyi accident property damage wpd s th st',\n",
       " 'pm traffic accident no injury at willis foreman rd',\n",
       " 'aashiqui actress anu aggarwal on her near fatal accident',\n",
       " 'suffield alberta accident',\n",
       " 'mile backup on i south accident blocking the right lanes at exit langtree rd consider nc or nc to nc as alternate',\n",
       " 'has an accident changed your life we will help you determine options that can financially support life care plans and on going treatment',\n",
       " 'breaking there was a deadly motorcycle car accident that happened to hagerstown today i ll have more details at your state whag',\n",
       " 'flowri were you marinading it or was it an accident',\n",
       " 'only had a car for not even a week and got in a fucking car accident mfs can t fucking drive']"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing = df['text'][:100]\n",
    "test_result = []\n",
    "for t in testing:\n",
    "    test_result.append(tweet_cleaner(t))\n",
    "test_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda x: tweet_cleaner(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analizo la columna location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "registros_sin_location = df.loc[df['location'].isnull(), :]\n",
    "registros_con_location = df.loc[df['location'].notnull(), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "USA                               104\n",
       "New York                           71\n",
       "United States                      50\n",
       "London                             45\n",
       "Canada                             29\n",
       "Nigeria                            28\n",
       "UK                                 27\n",
       "Los Angeles, CA                    26\n",
       "India                              24\n",
       "Mumbai                             22\n",
       "Washington, DC                     21\n",
       "Kenya                              20\n",
       "Worldwide                          19\n",
       "Chicago, IL                        18\n",
       "Australia                          18\n",
       "California                         17\n",
       "New York, NY                       15\n",
       "California, USA                    15\n",
       "Everywhere                         15\n",
       "San Francisco                      14\n",
       "United Kingdom                     14\n",
       "Florida                            14\n",
       "Los Angeles                        13\n",
       "Indonesia                          13\n",
       "Washington, D.C.                   13\n",
       "Ireland                            12\n",
       "NYC                                12\n",
       "Toronto                            12\n",
       "San Francisco, CA                  11\n",
       "Seattle                            11\n",
       "                                 ... \n",
       "Pioneer Village, KY                 1\n",
       "17-Feb                              1\n",
       "home                                1\n",
       "??????????????????                  1\n",
       " |IG: imaginedragoner               1\n",
       "Old Blighty                         1\n",
       "Alicante, Spain                     1\n",
       "manaus                              1\n",
       "in my head                          1\n",
       "?@symbolicjensen?                   1\n",
       "Tucson, Arizona                     1\n",
       "Canadian bread                      1\n",
       "Galapa / AtlÌÁntico                 1\n",
       "Manchester, The World, England      1\n",
       "Isle of Man                         1\n",
       "West Chester, PA                    1\n",
       "Toronto, ON                         1\n",
       "Est. September 2012 - Bristol       1\n",
       "Haarlem                             1\n",
       "Somerset, UK                        1\n",
       "london essex england uk             1\n",
       "Amazon Seller , Propagandist        1\n",
       "mexico                              1\n",
       "Morocco                             1\n",
       "Nigeria, WORLDWIDE                  1\n",
       "Every where                         1\n",
       "St PetersburgFL                     1\n",
       "Studio                              1\n",
       "Cassadaga Florida                   1\n",
       "LAGOS                               1\n",
       "Name: location, Length: 3341, dtype: int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "registros_con_location['location'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country-keyword-list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>America</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Andorra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Angola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Antigua</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Argentina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Armenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Azerbaijan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bahamas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Bahrain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Bangladesh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Barbados</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Belarus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Belgium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Belize</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Benin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Bhutan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Bissau</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Bolivia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Bosnia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Botswana</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Brazil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>British</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Brunei</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Bulgaria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Burkina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Switzerland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>Syria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>Taiwan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Tajikistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>Tanzania</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>Thailand</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Tobago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>Togo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>Tonga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>Trinidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>Tunisia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>Turkey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Turkmenistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>Tuvalu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Uganda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>Ukraine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Uruguay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Uzbekistan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Vanuatu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Vatican</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Venezuela</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Vietnam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>wales</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>welsh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>Yemen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Zambia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Zimbabwe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>210 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    country-keyword-list\n",
       "0            Afghanistan\n",
       "1                Albania\n",
       "2                Algeria\n",
       "3                America\n",
       "4                Andorra\n",
       "5                 Angola\n",
       "6                Antigua\n",
       "7              Argentina\n",
       "8                Armenia\n",
       "9              Australia\n",
       "10               Austria\n",
       "11            Azerbaijan\n",
       "12               Bahamas\n",
       "13               Bahrain\n",
       "14            Bangladesh\n",
       "15              Barbados\n",
       "16               Belarus\n",
       "17               Belgium\n",
       "18                Belize\n",
       "19                 Benin\n",
       "20                Bhutan\n",
       "21                Bissau\n",
       "22               Bolivia\n",
       "23                Bosnia\n",
       "24              Botswana\n",
       "25                Brazil\n",
       "26               British\n",
       "27                Brunei\n",
       "28              Bulgaria\n",
       "29               Burkina\n",
       "..                   ...\n",
       "180          Switzerland\n",
       "181                Syria\n",
       "182               Taiwan\n",
       "183           Tajikistan\n",
       "184             Tanzania\n",
       "185             Thailand\n",
       "186               Tobago\n",
       "187                 Togo\n",
       "188                Tonga\n",
       "189             Trinidad\n",
       "190              Tunisia\n",
       "191               Turkey\n",
       "192         Turkmenistan\n",
       "193               Tuvalu\n",
       "194               Uganda\n",
       "195              Ukraine\n",
       "196       United Kingdom\n",
       "197        United States\n",
       "198              Uruguay\n",
       "199                  USA\n",
       "200           Uzbekistan\n",
       "201              Vanuatu\n",
       "202              Vatican\n",
       "203            Venezuela\n",
       "204              Vietnam\n",
       "205                wales\n",
       "206                welsh\n",
       "207                Yemen\n",
       "208               Zambia\n",
       "209             Zimbabwe\n",
       "\n",
       "[210 rows x 1 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countrys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Para simplificar el analisis voy a eliminar las locations con frequencia menor a 2 y que no poseen prediccion para ambos target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = registros_con_location.groupby(['location','target']).size().reset_index(name='counts').sort_values('counts',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2['counts'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Denver, CO', 'Florida', 'Sydney', 'Calgary',\n",
       "       'California, United States', 'Midwest', 'South Africa',\n",
       "       'Singapore', 'Lagos, Nigeria', 'Leeds, England', 'Texas',\n",
       "       'Tennessee', 'Earth', 'Brasil', 'Wisconsin',\n",
       "       \"Jakarta/Kuala Lumpur/S'pore\", 'Austin, TX', 'Everywhere',\n",
       "       'worldwide', 'New York, USA', 'WorldWide', 'Planet Earth',\n",
       "       'Dallas, TX', 'Charlotte, NC', 'Morioh, Japan', 'MAD as Hell',\n",
       "       'Calgary, Alberta', 'Happily Married with 2 kids ', '304',\n",
       "       'Portland, Oregon', 'Paterson, New Jersey ', 'Brooklyn, NY',\n",
       "       'Vancouver, BC', 'Orlando, FL', 'Nigeria ',\n",
       "       ' Road to the Billionaires Club', 'ss', 'Coventry',\n",
       "       'London, England', 'Indiana', 'Haddonfield, NJ',\n",
       "       'Pennsylvania, USA', 'Atlanta', 'Memphis, TN', 'Bend, Oregon',\n",
       "       'canada', 'Mumbai', 'San Jose, CA', 'Portland, OR', 'Sacramento',\n",
       "       'US', 'Denver, Colorado', 'Puerto Rico', 'San Diego, CA',\n",
       "       'Nairobi-KENYA', 'Edinburgh', 'The Netherlands', 'Manchester',\n",
       "       'Oklahoma City, OK', 'Melbourne, Australia', 'New Jersey',\n",
       "       'Boston, MA', 'Switzerland', 'Nashville, TN',\n",
       "       'Seattle, Washington', 'Sacramento, CA', 'Seattle, WA', 'NYC',\n",
       "       'Texas, USA', 'Pedophile hunting ground'], dtype=object)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3 = df2['location'].value_counts().reset_index()\n",
    "df3[df3['location'] == 1]['index'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
